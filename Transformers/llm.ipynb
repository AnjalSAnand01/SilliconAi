{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2f6b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Path to your downloaded GGUF model\n",
    "model_path = \"/workspaces/SilliconAi/LLM_Models/mistral-7b-instruct.Q4_0.gguf\"\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=2048,     # Context size\n",
    "    n_threads=2,    # Match your CPU core count\n",
    ")\n",
    "\n",
    "# Prompt the model\n",
    "response = llm(\"What is setup in STA\", max_tokens=200)\n",
    "print(response[\"choices\"][0][\"text\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce7add",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
